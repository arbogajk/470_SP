\documentclass[main.tex]{subfiles}


\begin{document}

\indent We were successful in parallelizing Shamir's secret sharing algorithm, and achieved near linear scaling using OpenMP. Future work could extend this work to distributed memory architectures using message-passing frameworks like MPI, exploring whether the communication between nodes would be a limiting factor on speedup. Rabin's secret sharing algorithm \cite{five} would also be a good option for parallelism in future research. We hope our work can serve as a stepping stone for future projects, as there is still a lot that can be done with secret sharing algorithms in the context of parallel and distributed systems.

%\paragraph{MPI}
%\hfill \break
%\noindent An extension of our work could be to find a way to parallelize Shamir's using MPI. It would be interesting to discover if it would continue to scale or if the communication between nodes be a limiting factor on speedup. We concluded that the best approach to using MPI with Shamir's would be to write an implementation from scratch with the intent of having MPI compatibility. Separating the shares generation between processes seems to be possible, because the coefficients and y values are generated independently using pseudo-random numbers and modular exponentiation respectively.

%\paragraph{Rabin's Secret Sharing}
%\hfill \break
%\noindent Verifiable Secret Sharing, as created by T. Rabin and M. Ben-Or, can be implemented under the assumption that each participant can broadcast a message, and each pair of participants can communicate secretly \cite{five}. This may be a more reasonable secret sharing approach to parallelize. Unfortunately, it is much less well known, and the reading material is limited. From what we have heard, it could be worth pursuing a parallel implementation.   

%\subsubsection{Conclusion}
%\hfill \break
%\noindent We had a lot of fun learning about Shamir's Secret Sharing and trying to find ways to improve the implementation through parallelization. It was hard to understand the mathematics and underlying algorithms at first, but, after working with Shamir's for a while, we were able to understand what was actually going on. It was very satisfying to get the amount of speedup and scaling that we did using only OpenMP. In our project, we did not make any attempt to decide whether or not it is useful to parallelize Shamir's in real world applications. We simply set out to study the parallelization of an existing implementation, and we were successful.


\end{document}
